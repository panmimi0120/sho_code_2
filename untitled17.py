# -*- coding: utf-8 -*-
"""Untitled17.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_HDilOOauAy6pznw5EZiuSO46KKpfJiV
"""

import requests
from bs4 import BeautifulSoup
import time
import re
!pip install html2text
import html2text



# 一覧ページのURL
list_url = 'https://tabelog.com/tokyo/rstLst/ramen/1/?Srt=D&SrtT=rt&sort_mode=1&sk=%E3%83%A9%E3%83%BC%E3%83%A1%E3%83%B3&svd=20240211&svt=1900&svps=2&select_sort_flg=1'

# リクエストを送信し、レスポンスを取得
response = requests.get(list_url)
soup = BeautifulSoup(response.text, 'html.parser')

# 店舗詳細ページへのリンクを抽出
detail_links = [a['href'] for a in soup.select('a.list-rst__rst-name-target')][:20]  # デモのため最初の5店舗だけを抽出

# 各店舗のデータを抽出
for link in detail_links:
    # 詳細ページへのリクエストを送信
    detail_response = requests.get(link)
    detail_soup = BeautifulSoup(detail_response.text, 'html.parser')

    # 必要な情報を抽出
    store_name = detail_soup.find('div', class_='rstinfo-table__name-wrap').text.strip().split('\n')[0]  # 店名
    address = detail_soup.find('p', class_='rstinfo-table__address').text.strip().split('\n')[0]   # 住所
    rating = detail_soup.find('span', class_='rdheader-rating__score-val-dtl').text.strip().split('\n')[0]  # 評価
    comment_count = detail_soup.find('span', class_='rdheader-rating__review-target').text.strip().split('\n')[0]  # コメント数
    save_count = detail_soup.find('span', class_='rdheader-rating__hozon-target').text.strip().split('\n')[0]  # 保存数
    business_hours = detail_soup.find('p', class_='rstinfo-table__subject-text') # 営業時間
    if business_hours:
        business_hours = business_hours.text.strip().split('\n')[0]
    else:
        business_hours = None
    holiday = detail_soup.find('p', text='定休日').text.strip().split('\n')[0]  # 定休日
    try:
        holiday = html2text.html2text(detail_soup.find('p', class_='rstinfo-table__subject-text').decode())
    except AttributeError:
        holiday = '情報なし'

    budget = detail_soup.find('div', class_='rstinfo-table__budget').text.strip().split('\n')[0]  # 予算
    private_room = detail_soup.find('p', text=['有', '無']) # 個室有無
    if private_room:
        private_room_status = private_room.text.strip()
    else:
        private_room_status = '情報なし'
     # 席数の抽出（例：「6席」が含まれる<p>タグから）
    seats_text = detail_soup.find('p', text=re.compile('\d+席'))
    seats = re.search(r'\d+', seats_text.text).group() if seats_text else '情報なし'  #座席
    parking = detail_soup.find('p', text=['有', '無'])
    if parking:
        parking_status = parking.text.strip()
    else:
        parking_status = '情報なし'# 駐車場有無



    print(f"店名: {store_name}, 住所: {address}, 評価: {rating}, コメント数: {comment_count}, 保存数: {save_count}, 営業時間: {business_hours}, 定休日: {holiday}, 予算: {budget}, 個室有無: {private_room_status}, 席数: {seats}席, 駐車場有無: {parking_status},")

    # 他の情報も同様に表示
    # ...

    # サーバーに負荷をかけないように遅延を入れる
    time.sleep(1)



import requests
from bs4 import BeautifulSoup
import time
import re


# 一覧ページのURL
list_url = 'https://tabelog.com/tokyo/rstLst/ramen/1/?Srt=D&SrtT=rt&sort_mode=1&sk=%E3%83%A9%E3%83%BC%E3%83%A1%E3%83%B3&svd=20240211&svt=1900&svps=2&select_sort_flg=1'

# リクエストを送信し、レスポンスを取得
response = requests.get(list_url)
soup = BeautifulSoup(response.text, 'html.parser')

# 店舗詳細ページへのリンクを抽出
detail_links = [a['href'] for a in soup.select('a.list-rst__rst-name-target')][:20]  # デモのため最初の5店舗だけを抽出

# 各店舗のデータを抽出
for link in detail_links:
    # 詳細ページへのリクエストを送信
    detail_response = requests.get(link)
    detail_soup = BeautifulSoup(detail_response.text, 'html.parser')

    # 必要な情報を抽出
    store_name = detail_soup.find('div', class_='rstinfo-table__name-wrap').text.strip().split('\n')[0]  # 店名
    address = detail_soup.find('p', class_='rstinfo-table__address').text.strip().split('\n')[0]   # 住所
    rating = detail_soup.find('span', class_='rdheader-rating__score-val-dtl').text.strip().split('\n')[0]  # 評価
    comment_count = detail_soup.find('span', class_='rdheader-rating__review-target').text.strip().split('\n')[0]  # コメント数
    save_count = detail_soup.find('span', class_='rdheader-rating__hozon-target').text.strip().split('\n')[0]  # 保存数
    business_hours = detail_soup.find('p', class_='rstinfo-table__subject-text')
    if business_hours:
        business_hours = business_hours.text.strip().split('\n')[0]
    else:
        business_hours = None #営業時間
    holiday = detail_soup.find('p', class_='rstinfo-table__subject-text').text.strip().split('\n')[0]  # 定休日
    budget = detail_soup.find('div', class_='rstinfo-table__budget').text.strip().split('\n')[0]  # 予算
    private_room = detail_soup.find('p', text=['有', '無'])
    if private_room:
        private_room_status = private_room.text.strip()
    else:
        private_room_status = '情報なし'# 個室有無
     # 席数の抽出（例：「6席」が含まれる<p>タグから）
    seats_text = detail_soup.find('p', text=re.compile('\d+席'))
    seats = re.search(r'\d+', seats_text.text).group() if seats_text else '情報なし'  #座席
    parking = detail_soup.find('p', text=['有', '無'])
    if parking:
        parking_status = parking.text.strip()
    else:
        parking_status = '情報なし'# 駐車場有無



    print(f"店名: {store_name}, 住所: {address}, 評価: {rating}, コメント数: {comment_count}, 保存数: {save_count}, 営業時間: {business_hours}, 定休日: {holiday}, 予算: {budget}, 個室有無: {private_room_status}, 席数: {seats}席, 駐車場有無: {parking_status},")

    # 他の情報も同様に表示
    # ...

    # サーバーに負荷をかけないように遅延を入れる
    time.sleep(1)